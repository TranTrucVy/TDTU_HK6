# -*- coding: utf-8 -*-
"""Example-Keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I4URQhn0UaoyQp9Gxav5wRg8yO5WYiNw

# 1. Import Library
"""

!pip install tensorflow-addons

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD, Adam, RMSprop

"""#2. Load dataset using pandas

## About dataset: Heart Disease Dataset

*   age
*   sex
*   chest pain type (4 values)
*   resting blood pressure
*   serum cholestoral in mg/dl
*   fasting blood sugar > 120 mg/dl
*   resting electrocardiographic results (values 0,1,2)
*   maximum heart rate achieved
*   exercise induced angina
*   oldpeak = ST depression induced by exercise relative to rest
*   the slope of the peak exercise ST segment
*   number of major vessels (0-3) colored by flourosopy
*   thal: 0 = normal; 1 = fixed defect; 2 = reversable defect



















"""

df = pd.read_csv('heart.csv')
print(df.shape)
df.tail(15)

"""#3. Processing data"""

# convert data to numpy array
X = df.iloc[:, 0:-1].values
y = df.iloc[:, -1].values

# Standardize the features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""#5. Building a Neural Network"""

# Define neural network
def create_model():
    model = Sequential([
        Dense(5, activation='tanh', input_shape=(13,)),
        Dense(4, activation='tanh'),
        Dense(3, activation='tanh'),
        Dense(1, activation='sigmoid')
    ])
    return model

# Define optimizers
optimizers = {
    "SGD": tf.keras.optimizers.legacy.SGD(learning_rate=0.1, momentum=0.9, decay=1e-5),
    "Adam": tf.keras.optimizers.legacy.Adam(learning_rate=0.1, decay=1e-5),
    "RMSprop": tf.keras.optimizers.legacy.RMSprop(learning_rate=0.1, decay=1e-5),
    "AdamW": tfa.optimizers.AdamW(learning_rate=0.1, weight_decay=1e-5),
}

epochs = 50
early_stop_thresh = 5
best_accuracy = -1
best_epoch = -1
accuracies = {optimizer_name: [] for optimizer_name in optimizers}

"""#6. Train network"""

for optimizer_name, optimizer in optimizers.items():
    model = create_model()
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    for epoch in range(epochs):
        history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_split=0.2, verbose=0)
        accuracy = history.history['val_accuracy'][0] * 100

        accuracies[optimizer_name].append(accuracy)

        # Print statistics
        print('Optimizer: {}, Epoch {}/{}, Accuracy: {:.2f}'.format(
            optimizer_name, epoch + 1, epochs, accuracy))

        # Check for best accuracy and early stopping
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_epoch = epoch
            model.save(f"best_model_{optimizer_name}.h5")

        if epoch - best_epoch > early_stop_thresh:
            print(f'{optimizer_name} algorithms stopped training at epoch {epoch}')
            print('\n\n')
            break  # terminate the training loop

"""#Comparison of optimizer algorithms"""

# Plotting
plt.figure(figsize=(10, 6))
for optimizer_name, accuracy in accuracies.items():
    plt.plot(range(1, len(accuracy) + 1), accuracy, label=optimizer_name)
plt.title('Validation Accuracy by Optimizer')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.grid(True)
plt.show()

