{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3913f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e3d3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have you read the communist', 'what is a government']\n",
      "['yes, marx had made some interesting observations.', 'ideally it is a representative of the people.']\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('chatbot.csv')\n",
    "questions = list(df['question'])\n",
    "answers = list(df['answer'])\n",
    "print(questions[:2])\n",
    "print(answers[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5ddbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"\": SOS_token, \"\": EOS_token}\n",
    "        self.index2word = {SOS_token: \"\", EOS_token: \"\"}\n",
    "        self.words_count = len(self.word2index)\n",
    "\n",
    "    def add_words(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.words_count\n",
    "                self.index2word[self.words_count] = word\n",
    "                self.words_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "139ceda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "def getDict(dataPipe):\n",
    "\n",
    "    data_dict = {\n",
    "        'question': [],\n",
    "        'answer': []\n",
    "    }\n",
    "    \n",
    "    for _, question, answers, _ in dataPipe:\n",
    "        data_dict['question'].append(question)\n",
    "        data_dict['answer'].append(answers[0])\n",
    "        \n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def loadDF(path):\n",
    "    # load data\n",
    "    train_data, val_data = torchtext.datasets.SQuAD1(path)\n",
    "    \n",
    "    # convert dataPipe to dictionary \n",
    "    train_dict, val_dict = getDict(train_data), getDict(val_data)\n",
    "    \n",
    "    # convert Dictionaries to Pandas DataFrame\n",
    "    train_df = pd.DataFrame(train_dict)    \n",
    "    validation_df = pd.DataFrame(val_dict)    \n",
    "    \n",
    "    return train_df.append(validation_df)\n",
    "\n",
    "\n",
    "def prepare_text(sentence):\n",
    "    # clean text and tokenize it \n",
    "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
    "    tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def toTensor(vocab, sentence):\n",
    "    # convert list of words \"sentence\" to a torch tensor of indices\n",
    "    indices = [vocab.word2index[word] for word in sentence.split(' ')]\n",
    "    indices.append(vocab.word2index[''])\n",
    "    return torch.Tensor(indices).long().to(device).view(-1, 1)\n",
    "\n",
    "\n",
    "def getPairs(df):\n",
    "    # convert df to list of pairs\n",
    "    temp1 = df['question'].apply(lambda x: \" \".join(x) ).to_list()\n",
    "    temp2 = df['answer'].apply(lambda x: \" \".join(x) ).to_list()\n",
    "    return [list(i) for i in zip(temp1, temp2)]\n",
    "\n",
    "\n",
    "def getMaxLen(pairs):\n",
    "    max_src = 0 \n",
    "    max_trg = 0\n",
    "    \n",
    "    for p in pairs:\n",
    "        max_src = len(p[0].split()) if len(p[0].split()) > max_src else max_src\n",
    "        max_trg = len(p[1].split()) if len(p[1].split()) > max_trg else max_trg\n",
    "        \n",
    "    return max_src, max_trg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222f3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(1, 1, -1)\n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        return x, hidden, cell_state\n",
    "        \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim= 1)\n",
    "\n",
    "    def forward(self, x, hidden, cell_state):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(1, 1, -1)\n",
    "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
    "        x = self.softmax(self.fc(x[0]))\n",
    "        return x, hidden, cell_state\n",
    "    \n",
    "     \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder = Encoder(self.input_size, self.hidden_size)\n",
    "        self.decoder = Decoder(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, src, trg, src_len, trg_len, teacher_force=1):\n",
    "        \n",
    "        output = {\n",
    "            'decoder_output':[]\n",
    "        }\n",
    "        \n",
    "        encoder_hidden = torch.zeros([1, 1, self.hidden_size]).to(device) # 1 = number of LSTM layers\n",
    "        cell_state = torch.zeros([1, 1, self.hidden_size]).to(device)  \n",
    "        \n",
    "        for i in range(src_len):\n",
    "            encoder_output, encoder_hidden, cell_state = self.encoder(src[i], encoder_hidden, cell_state)\n",
    "\n",
    "        decoder_input = torch.Tensor([[0]]).long().to(device) # 0 = SOS_token\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for i in range(trg_len):\n",
    "            decoder_output, decoder_hidden, cell_state = self.decoder(decoder_input, decoder_hidden, cell_state)\n",
    "            output['decoder_output'].append(decoder_output)\n",
    "            \n",
    "            if self.training: # Model not in eval mode\n",
    "                decoder_input = target_tensor[i] if random.random() > teacher_force else decoder_output.argmax(1) # teacher forcing\n",
    "            else:\n",
    "                _, top_index = decoder_output.data.topk(1)\n",
    "                decoder_input = top_index.squeeze().detach()\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e465ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "def train(source_data, target_data, model, epochs, batch_size, print_every, learning_rate):\n",
    "    \n",
    "    model.to(device)\n",
    "    total_training_loss = 0\n",
    "    total_valid_loss = 0\n",
    "    loss = 0\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # use cross validation\n",
    "    kf = KFold(n_splits=epochs, shuffle=True)\n",
    "\n",
    "    for e, (train_index, test_index) in enumerate(kf.split(source_data), 1):\n",
    "        model.train()\n",
    "        for i in range(0, len(train_index)):\n",
    "\n",
    "            src = source_data[i]\n",
    "            trg = target_data[i]\n",
    "\n",
    "            output = model(src, trg, src.size(0), trg.size(0))\n",
    "\n",
    "            current_loss = 0\n",
    "            for (s, t) in zip(output[\"decoder_output\"], trg): \n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "            loss += current_loss\n",
    "            total_training_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "\n",
    "            if i % batch_size == 0 or i == (len(train_index)-1):\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss = 0\n",
    "\n",
    "\n",
    "        # validation set \n",
    "        model.eval()\n",
    "        for i in range(0, len(test_index)):\n",
    "            src = source_data[i]\n",
    "            trg = target_data[i]\n",
    "\n",
    "            output = model(src, trg, src.size(0), trg.size(0))\n",
    "\n",
    "            current_loss = 0\n",
    "            for (s, t) in zip(output[\"decoder_output\"], trg): \n",
    "                current_loss += criterion(s, t)\n",
    "\n",
    "            total_valid_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
    "\n",
    "\n",
    "        if e % print_every == 0:\n",
    "            training_loss_average = total_training_loss / (len(train_index)*print_every)\n",
    "            validation_loss_average = total_valid_loss / (len(test_index)*print_every)\n",
    "            print(\"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\".format(e, epochs, training_loss_average, validation_loss_average))\n",
    "            total_training_loss = 0\n",
    "            total_valid_loss = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427aca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(src, Q_vocab, A_vocab, model, target_max_len):\n",
    "    \n",
    "    try:\n",
    "        src = toTensor(Q_vocab, \" \".join(prepare_text(src)))\n",
    "    except:\n",
    "        print(\"Error: Word Encountered Not In The Vocabulary.\")\n",
    "        return\n",
    "    \n",
    "    answer_words = []\n",
    "    \n",
    "    output = model(src, None, src.size(0), target_max_len)\n",
    "\n",
    "    for tensor in output['decoder_output']:\n",
    "\n",
    "        _, top_token = tensor.data.topk(1)\n",
    "        if top_token.item() == 1:\n",
    "            break\n",
    "        else:\n",
    "            word = A_vocab.index2word[top_token.item()]\n",
    "            answer_words.append(word)\n",
    "            \n",
    "    print(\"<\", ' '.join(answer_words), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68fbdfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'is', 'a', 'government']\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('chatbot.csv')\n",
    "data_df['question'] = data_df['question'].apply(prepare_text)\n",
    "data_df['answer'] = data_df['answer'].apply(prepare_text)\n",
    "print(data_df['question'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b9f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = getPairs(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b45589e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 15)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_src, max_trg = getMaxLen(pairs)\n",
    "max_trg, max_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b33c42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_vocab = Vocab()\n",
    "A_vocab = Vocab()\n",
    "\n",
    "for pair in pairs:\n",
    "    Q_vocab.add_words(pair[0])\n",
    "    A_vocab.add_words(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "394c95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = [toTensor(Q_vocab, pair[0]) for pair in pairs]\n",
    "target_data = [toTensor(A_vocab, pair[1]) for pair in pairs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa1dbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "hidden_size = 128 # encoder and decoder hidden size\n",
    "batch_size = 50\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a765fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/100 Epoch  -  Training Loss = 6.9034  -  Validation Loss = 6.9258\n",
      "10/100 Epoch  -  Training Loss = 5.5464  -  Validation Loss = 6.2303\n",
      "15/100 Epoch  -  Training Loss = 4.9995  -  Validation Loss = 5.6701\n",
      "20/100 Epoch  -  Training Loss = 4.7674  -  Validation Loss = 5.3606\n",
      "25/100 Epoch  -  Training Loss = 4.4084  -  Validation Loss = 5.1166\n",
      "30/100 Epoch  -  Training Loss = 4.0841  -  Validation Loss = 4.8146\n",
      "35/100 Epoch  -  Training Loss = 3.7788  -  Validation Loss = 4.5818\n",
      "40/100 Epoch  -  Training Loss = 3.4683  -  Validation Loss = 4.3143\n",
      "45/100 Epoch  -  Training Loss = 3.1371  -  Validation Loss = 4.0307\n",
      "50/100 Epoch  -  Training Loss = 2.8178  -  Validation Loss = 3.8028\n",
      "55/100 Epoch  -  Training Loss = 2.4759  -  Validation Loss = 3.3063\n",
      "60/100 Epoch  -  Training Loss = 2.1398  -  Validation Loss = 2.7862\n",
      "65/100 Epoch  -  Training Loss = 1.8432  -  Validation Loss = 2.1489\n",
      "70/100 Epoch  -  Training Loss = 1.5986  -  Validation Loss = 1.7668\n",
      "75/100 Epoch  -  Training Loss = 1.4192  -  Validation Loss = 1.2604\n",
      "80/100 Epoch  -  Training Loss = 1.2231  -  Validation Loss = 0.9943\n",
      "85/100 Epoch  -  Training Loss = 1.1174  -  Validation Loss = 0.7452\n",
      "90/100 Epoch  -  Training Loss = 1.0459  -  Validation Loss = 0.5894\n",
      "95/100 Epoch  -  Training Loss = 0.9455  -  Validation Loss = 0.4577\n",
      "100/100 Epoch  -  Training Loss = 0.8583  -  Validation Loss = 0.3311\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(Q_vocab.words_count, hidden_size, A_vocab.words_count)\n",
    "\n",
    "train(source_data = source_data,\n",
    "      target_data = target_data,\n",
    "      model = seq2seq,\n",
    "      print_every = 5,\n",
    "      epochs = epochs,\n",
    "      learning_rate = learning_rate,\n",
    "      batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f0fc66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(507, 128)\n",
       "    (lstm): LSTM(128, 128)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(1338, 128)\n",
       "    (lstm): LSTM(128, 128)\n",
       "    (fc): Linear(in_features=128, out_features=1338, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_path = 'seq2seq.pt'\n",
    "\n",
    "torch.save(seq2seq, model_path)\n",
    "\n",
    "seq2seq = torch.load(model_path, map_location=torch.device('mps'))\n",
    "seq2seq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e97fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to finish the chat.\n",
      " ------------------------------ \n",
      "\n",
      "> What is AI?\n",
      "< artificial intelligence is the branch of engineering and science devoted and that that that that the the \n",
      "\n",
      "> Are you sentient?\n",
      "< even of im a definition i have of \n",
      "\n",
      "> You are not making sense\n",
      "< it the make sense it to my artificial mind you \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Type 'exit' to finish the chat.\\n\", \"-\"*30, '\\n')\n",
    "while (True):\n",
    "    src = input(\"> \")\n",
    "    if src.strip() == \"exit\":\n",
    "        break\n",
    "    evaluate(src, Q_vocab, A_vocab, seq2seq, max_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72671c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
