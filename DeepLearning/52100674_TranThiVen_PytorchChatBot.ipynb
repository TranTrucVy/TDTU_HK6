{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 52100674 TranThiVen\n"
      ],
      "metadata": {
        "id": "pyoNr5d-nt2u"
      },
      "id": "pyoNr5d-nt2u"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are given a source code for chatbot problem using Tensorflow.\n",
        "Convert the code into pytorch."
      ],
      "metadata": {
        "id": "OQYg600Vn4QT"
      },
      "id": "OQYg600Vn4QT"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ca3913f1",
      "metadata": {
        "id": "ca3913f1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "97e3d3cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97e3d3cc",
        "outputId": "c6a31a94-4379-470f-be57-b2e83f55ba04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['have you read the communist', 'what is a government']\n",
            "['yes, marx had made some interesting observations.', 'ideally it is a representative of the people.']\n"
          ]
        }
      ],
      "source": [
        "# Read the CSV file\n",
        "df = pd.read_csv('chatbot.csv')\n",
        "questions = list(df['question'])\n",
        "answers = list(df['answer'])\n",
        "print(questions[:2])\n",
        "print(answers[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fe5ddbb0",
      "metadata": {
        "id": "fe5ddbb0"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.word2index = {\"\": SOS_token, \"\": EOS_token}\n",
        "        self.index2word = {SOS_token: \"\", EOS_token: \"\"}\n",
        "        self.words_count = len(self.word2index)\n",
        "\n",
        "    def add_words(self, sentence):\n",
        "        for word in sentence.split(\" \"):\n",
        "            if word not in self.word2index:\n",
        "                self.word2index[word] = self.words_count\n",
        "                self.index2word[self.words_count] = word\n",
        "                self.words_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "import torch\n",
        "import torchtext"
      ],
      "metadata": {
        "id": "l_SoAiVXmeZw"
      },
      "id": "l_SoAiVXmeZw",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "def getDict(dataPipe):\n",
        "    data_dict = {\n",
        "        'question': [],\n",
        "        'answer': []\n",
        "    }\n",
        "    for _, question, answers, _ in dataPipe:\n",
        "        data_dict['question'].append(question)\n",
        "        data_dict['answer'].append(answers[0])\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "kCK2ofApmsa_"
      },
      "id": "kCK2ofApmsa_",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadDF(path):\n",
        "    # load data\n",
        "    train_data, val_data = torchtext.datasets.SQuAD1(path)\n",
        "    # convert dataPipe to dictionary\n",
        "    train_dict, val_dict = getDict(train_data), getDict(val_data)\n",
        "    # convert Dictionaries to Pandas DataFrame\n",
        "    train_df = pd.DataFrame(train_dict)\n",
        "    validation_df = pd.DataFrame(val_dict)\n",
        "    return train_df.append(validation_df)"
      ],
      "metadata": {
        "id": "idqlxn7Smt6g"
      },
      "id": "idqlxn7Smt6g",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_text(sentence):\n",
        "    # clean text and tokenize it\n",
        "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
        "    tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "aQGy8ZLkmw8n"
      },
      "id": "aQGy8ZLkmw8n",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_text(sentence):\n",
        "    # clean text and tokenize it\n",
        "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
        "    tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "A66iB5KQmyAw"
      },
      "id": "A66iB5KQmyAw",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_text(sentence):\n",
        "    # clean text and tokenize it\n",
        "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
        "    tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "2Gwak5ermzzR"
      },
      "id": "2Gwak5ermzzR",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def toTensor(vocab, sentence):\n",
        "    # convert list of words \"sentence\" to a torch tensor of indices\n",
        "    indices = [vocab.word2index[word] for word in sentence.split(' ')]\n",
        "    indices.append(vocab.word2index[''])\n",
        "    return torch.Tensor(indices).long().to(device).view(-1, 1)"
      ],
      "metadata": {
        "id": "TQlkCjWgm2VY"
      },
      "id": "TQlkCjWgm2VY",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPairs(df):\n",
        "    # convert df to list of pairs\n",
        "    temp1 = df['question'].apply(lambda x: \" \".join(x) ).to_list()\n",
        "    temp2 = df['answer'].apply(lambda x: \" \".join(x) ).to_list()\n",
        "    return [list(i) for i in zip(temp1, temp2)]"
      ],
      "metadata": {
        "id": "H6Q-mSO2m5NY"
      },
      "id": "H6Q-mSO2m5NY",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "139ceda5",
      "metadata": {
        "id": "139ceda5"
      },
      "outputs": [],
      "source": [
        "def getMaxLen(pairs):\n",
        "    max_src = 0\n",
        "    max_trg = 0\n",
        "    for p in pairs:\n",
        "        max_src = len(p[0].split()) if len(p[0].split()) > max_src else max_src\n",
        "        max_trg = len(p[1].split()) if len(p[1].split()) > max_trg else max_trg\n",
        "    return max_src, max_trg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell_state):\n",
        "        x = self.embedding(x)\n",
        "        x = x.view(1, 1, -1)\n",
        "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
        "        return x, hidden, cell_state"
      ],
      "metadata": {
        "id": "HjzL_CiGm9v4"
      },
      "id": "HjzL_CiGm9v4",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.embedding = nn.Embedding(output_size, self.hidden_size)\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim= 1)\n",
        "\n",
        "    def forward(self, x, hidden, cell_state):\n",
        "        x = self.embedding(x)\n",
        "        x = x.view(1, 1, -1)\n",
        "        x, (hidden, cell_state) = self.lstm(x, (hidden, cell_state))\n",
        "        x = self.softmax(self.fc(x[0]))\n",
        "        return x, hidden, cell_state"
      ],
      "metadata": {
        "id": "9WN_Tm6bnMqR"
      },
      "id": "9WN_Tm6bnMqR",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "222f3120",
      "metadata": {
        "id": "222f3120"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.encoder = Encoder(self.input_size, self.hidden_size)\n",
        "        self.decoder = Decoder(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, src, trg, src_len, trg_len, teacher_force=1):\n",
        "        output = {\n",
        "            'decoder_output':[]\n",
        "        }\n",
        "        encoder_hidden = torch.zeros([1, 1, self.hidden_size]).to(device) # 1 = number of LSTM layers\n",
        "        cell_state = torch.zeros([1, 1, self.hidden_size]).to(device)\n",
        "        for i in range(src_len):\n",
        "            encoder_output, encoder_hidden, cell_state = self.encoder(src[i], encoder_hidden, cell_state)\n",
        "\n",
        "        decoder_input = torch.Tensor([[0]]).long().to(device) # 0 = SOS_token\n",
        "        decoder_hidden = encoder_hidden\n",
        "        for i in range(trg_len):\n",
        "            decoder_output, decoder_hidden, cell_state = self.decoder(decoder_input, decoder_hidden, cell_state)\n",
        "            output['decoder_output'].append(decoder_output)\n",
        "            if self.training: # Model not in eval mode\n",
        "                decoder_input = target_tensor[i] if random.random() > teacher_force else decoder_output.argmax(1) # teacher forcing\n",
        "            else:\n",
        "                _, top_index = decoder_output.data.topk(1)\n",
        "                decoder_input = top_index.squeeze().detach()\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "qZ722I_LnYPP"
      },
      "id": "qZ722I_LnYPP",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e465ea29",
      "metadata": {
        "id": "e465ea29"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "def train(source_data, target_data, model, epochs, batch_size, print_every, learning_rate):\n",
        "    model.to(device)\n",
        "    total_training_loss = 0\n",
        "    total_valid_loss = 0\n",
        "    loss = 0\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "    # use cross validation\n",
        "    kf = KFold(n_splits=epochs, shuffle=True)\n",
        "\n",
        "    for e, (train_index, test_index) in enumerate(kf.split(source_data), 1):\n",
        "        model.train()\n",
        "        for i in range(0, len(train_index)):\n",
        "            src = source_data[i]\n",
        "            trg = target_data[i]\n",
        "            output = model(src, trg, src.size(0), trg.size(0))\n",
        "            current_loss = 0\n",
        "            for (s, t) in zip(output[\"decoder_output\"], trg):\n",
        "                current_loss += criterion(s, t)\n",
        "            loss += current_loss\n",
        "            total_training_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
        "\n",
        "            if i % batch_size == 0 or i == (len(train_index)-1):\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                loss = 0\n",
        "\n",
        "        # validation set\n",
        "        model.eval()\n",
        "        for i in range(0, len(test_index)):\n",
        "            src = source_data[i]\n",
        "            trg = target_data[i]\n",
        "            output = model(src, trg, src.size(0), trg.size(0))\n",
        "            current_loss = 0\n",
        "            for (s, t) in zip(output[\"decoder_output\"], trg):\n",
        "                current_loss += criterion(s, t)\n",
        "            total_valid_loss += (current_loss.item() / trg.size(0)) # add the iteration loss\n",
        "\n",
        "        if e % print_every == 0:\n",
        "            training_loss_average = total_training_loss / (len(train_index)*print_every)\n",
        "            validation_loss_average = total_valid_loss / (len(test_index)*print_every)\n",
        "            print(\"{}/{} Epoch  -  Training Loss = {:.4f}  -  Validation Loss = {:.4f}\".format(e, epochs, training_loss_average, validation_loss_average))\n",
        "            total_training_loss = 0\n",
        "            total_valid_loss = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "427aca1e",
      "metadata": {
        "id": "427aca1e"
      },
      "outputs": [],
      "source": [
        "def evaluate(src, Q_vocab, A_vocab, model, target_max_len):\n",
        "    try:\n",
        "        src = toTensor(Q_vocab, \" \".join(prepare_text(src)))\n",
        "    except:\n",
        "        print(\"Error: Word Encountered Not In The Vocabulary.\")\n",
        "        return\n",
        "    answer_words = []\n",
        "    output = model(src, None, src.size(0), target_max_len)\n",
        "    for tensor in output['decoder_output']:\n",
        "        _, top_token = tensor.data.topk(1)\n",
        "        if top_token.item() == 1:\n",
        "            break\n",
        "        else:\n",
        "            word = A_vocab.index2word[top_token.item()]\n",
        "            answer_words.append(word)\n",
        "    print(\"<\", ' '.join(answer_words), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "68fbdfba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68fbdfba",
        "outputId": "e4b3edbe-9d6e-45f5-8a31-a29beaffeb47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what', 'is', 'a', 'government']\n"
          ]
        }
      ],
      "source": [
        "data_df = pd.read_csv('chatbot.csv')\n",
        "data_df['question'] = data_df['question'].apply(prepare_text)\n",
        "data_df['answer'] = data_df['answer'].apply(prepare_text)\n",
        "print(data_df['question'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d6b9f298",
      "metadata": {
        "id": "d6b9f298"
      },
      "outputs": [],
      "source": [
        "pairs = getPairs(data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b45589e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b45589e2",
        "outputId": "a5b598ee-2883-4bc0-8e3f-d520850d4de9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "max_src, max_trg = getMaxLen(pairs)\n",
        "max_trg, max_src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b33c42fd",
      "metadata": {
        "id": "b33c42fd"
      },
      "outputs": [],
      "source": [
        "Q_vocab = Vocab()\n",
        "A_vocab = Vocab()\n",
        "\n",
        "for pair in pairs:\n",
        "    Q_vocab.add_words(pair[0])\n",
        "    A_vocab.add_words(pair[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "394c95fc",
      "metadata": {
        "id": "394c95fc"
      },
      "outputs": [],
      "source": [
        "source_data = [toTensor(Q_vocab, pair[0]) for pair in pairs]\n",
        "target_data = [toTensor(A_vocab, pair[1]) for pair in pairs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "aa1dbeb7",
      "metadata": {
        "id": "aa1dbeb7"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "hidden_size = 128 # encoder and decoder hidden size\n",
        "batch_size = 50\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a765fb78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a765fb78",
        "outputId": "df325206-964e-49a8-eb8d-e9c6bf24f00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/100 Epoch  -  Training Loss = 6.5679  -  Validation Loss = 6.6180\n",
            "10/100 Epoch  -  Training Loss = 5.5237  -  Validation Loss = 6.1712\n",
            "15/100 Epoch  -  Training Loss = 5.1105  -  Validation Loss = 5.7772\n",
            "20/100 Epoch  -  Training Loss = 4.9115  -  Validation Loss = 5.5417\n",
            "25/100 Epoch  -  Training Loss = 4.7085  -  Validation Loss = 5.4076\n",
            "30/100 Epoch  -  Training Loss = 4.5295  -  Validation Loss = 5.2074\n",
            "35/100 Epoch  -  Training Loss = 4.3283  -  Validation Loss = 5.0661\n",
            "40/100 Epoch  -  Training Loss = 4.1272  -  Validation Loss = 4.8144\n",
            "45/100 Epoch  -  Training Loss = 3.9183  -  Validation Loss = 4.6252\n",
            "50/100 Epoch  -  Training Loss = 3.7110  -  Validation Loss = 4.3881\n",
            "55/100 Epoch  -  Training Loss = 3.4980  -  Validation Loss = 4.1797\n",
            "60/100 Epoch  -  Training Loss = 3.2978  -  Validation Loss = 3.9765\n",
            "65/100 Epoch  -  Training Loss = 3.0963  -  Validation Loss = 3.8268\n",
            "70/100 Epoch  -  Training Loss = 2.9758  -  Validation Loss = 3.5663\n",
            "75/100 Epoch  -  Training Loss = 2.7239  -  Validation Loss = 3.1032\n",
            "80/100 Epoch  -  Training Loss = 2.5279  -  Validation Loss = 2.7678\n",
            "85/100 Epoch  -  Training Loss = 2.2870  -  Validation Loss = 2.3461\n",
            "90/100 Epoch  -  Training Loss = 2.0795  -  Validation Loss = 2.0196\n",
            "95/100 Epoch  -  Training Loss = 1.8855  -  Validation Loss = 1.8641\n",
            "100/100 Epoch  -  Training Loss = 1.7198  -  Validation Loss = 1.5862\n"
          ]
        }
      ],
      "source": [
        "seq2seq = Seq2Seq(Q_vocab.words_count, hidden_size, A_vocab.words_count)\n",
        "\n",
        "train(source_data = source_data,\n",
        "      target_data = target_data,\n",
        "      model = seq2seq,\n",
        "      print_every = 5,\n",
        "      epochs = epochs,\n",
        "      learning_rate = learning_rate,\n",
        "      batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0fc66b",
      "metadata": {
        "id": "1f0fc66b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "model_path = 'seq2seq.pt'\n",
        "torch.save(seq2seq, model_path)\n",
        "seq2seq = torch.load(model_path, map_location=torch.device('mps'))\n",
        "seq2seq.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "db1e97fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db1e97fe",
        "outputId": "c23d6d25-98e3-4581-e940-34e628846efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type 'exit' to finish the chat.\n",
            " ------------------------------ \n",
            "\n",
            "> hello\n",
            "< greetings \n",
            "\n",
            "> his\n",
            "Error: Word Encountered Not In The Vocabulary.\n",
            "> name\n",
            "< i you mean the the \n",
            "\n",
            "> exit\n"
          ]
        }
      ],
      "source": [
        "print(\"Type 'exit' to finish the chat.\\n\", \"-\"*30, '\\n')\n",
        "while (True):\n",
        "    src = input(\"> \")\n",
        "    if src.strip() == \"exit\":\n",
        "        break\n",
        "    evaluate(src, Q_vocab, A_vocab, seq2seq, max_trg)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}