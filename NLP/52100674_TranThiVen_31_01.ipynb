{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TRẦN THỊ VẸN"
      ],
      "metadata": {
        "id": "jkBMunMUo8Ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Cambridge English Qualifications are in-depth exams that make learning English enjoyable, effective and rewarding. Our unique approach encourages continuous progression with a clear path to improve language skills. We have qualifications for schools, general and higher education, and business.'"
      ],
      "metadata": {
        "id": "drJXo-qzcaFU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "tokens = text_to_word_sequence(sentence)\n",
        "print (tokens)\n",
        "#this Lib cannot separate punctuation marks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdUPx7VGcuv3",
        "outputId": "d83d2f7a-18b2-4b7b-cae9-33ece0ef3c37"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cambridge', 'english', 'qualifications', 'are', 'in', 'depth', 'exams', 'that', 'make', 'learning', 'english', 'enjoyable', 'effective', 'and', 'rewarding', 'our', 'unique', 'approach', 'encourages', 'continuous', 'progression', 'with', 'a', 'clear', 'path', 'to', 'improve', 'language', 'skills', 'we', 'have', 'qualifications', 'for', 'schools', 'general', 'and', 'higher', 'education', 'and', 'business']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veeWf86CXHpS",
        "outputId": "ca005baa-d956-4403-ad53-979ca3ddc0b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYnbj617Z_ns",
        "outputId": "23852eb6-3a7e-485b-d25f-41617f981752"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cambridge', 'English', 'Qualifications', 'are', 'in-depth', 'exams', 'that', 'make', 'learning', 'English', 'enjoyable', ',', 'effective', 'and', 'rewarding', '.', 'Our', 'unique', 'approach', 'encourages', 'continuous', 'progression', 'with', 'a', 'clear', 'path', 'to', 'improve', 'language', 'skills', '.', 'We', 'have', 'qualifications', 'for', 'schools', ',', 'general', 'and', 'higher', 'education', ',', 'and', 'business', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =  'This story centers around Titania and Oberon, two fairy characters from Shakespeare’s famous play, “A Midsummer Night’s Dream.” The two fairies are having a rough time in their marriage when they find a human child. They decide to adopt him, hoping that he’ll help them save their relationship. However, the child develops a deadly, modern disease and the fairies have no idea what to do since they have never known illness or death. This is a tragic tale about how they try to understand something they’ve never seen before and their deep love for a stranger who is so unlike them. The story explores the grief of parenthood and the uncertainty of knowing whether your child will ever even know you.'"
      ],
      "metadata": {
        "id": "B-UaCJHbde-E"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents = sent_tokenize(text)\n",
        "for s in sents:\n",
        "  print(s, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm-ZMXh7dNpa",
        "outputId": "0b1b137f-d39a-4186-8eb1-2b15ae7e9c71"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This story centers around Titania and Oberon, two fairy characters from Shakespeare’s famous play, “A Midsummer Night’s Dream.” The two fairies are having a rough time in their marriage when they find a human child. \n",
            "\n",
            "They decide to adopt him, hoping that he’ll help them save their relationship. \n",
            "\n",
            "However, the child develops a deadly, modern disease and the fairies have no idea what to do since they have never known illness or death. \n",
            "\n",
            "This is a tragic tale about how they try to understand something they’ve never seen before and their deep love for a stranger who is so unlike them. \n",
            "\n",
            "The story explores the grief of parenthood and the uncertainty of knowing whether your child will ever even know you. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPAWqUAyZVeh",
        "outputId": "4ec17062-976d-405a-bd62-cb99223be9fa"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'story', 'centers', 'around', 'Titania', 'and', 'Oberon', ',', 'two', 'fairy', 'characters', 'from', 'Shakespeare', '’', 's', 'famous', 'play', ',', '“', 'A', 'Midsummer', 'Night', '’', 's', 'Dream.', '”', 'The', 'two', 'fairies', 'are', 'having', 'a', 'rough', 'time', 'in', 'their', 'marriage', 'when', 'they', 'find', 'a', 'human', 'child', '.', 'They', 'decide', 'to', 'adopt', 'him', ',', 'hoping', 'that', 'he', '’', 'll', 'help', 'them', 'save', 'their', 'relationship', '.', 'However', ',', 'the', 'child', 'develops', 'a', 'deadly', ',', 'modern', 'disease', 'and', 'the', 'fairies', 'have', 'no', 'idea', 'what', 'to', 'do', 'since', 'they', 'have', 'never', 'known', 'illness', 'or', 'death', '.', 'This', 'is', 'a', 'tragic', 'tale', 'about', 'how', 'they', 'try', 'to', 'understand', 'something', 'they', '’', 've', 'never', 'seen', 'before', 'and', 'their', 'deep', 'love', 'for', 'a', 'stranger', 'who', 'is', 'so', 'unlike', 'them', '.', 'The', 'story', 'explores', 'the', 'grief', 'of', 'parenthood', 'and', 'the', 'uncertainty', 'of', 'knowing', 'whether', 'your', 'child', 'will', 'ever', 'even', 'know', 'you', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_counts = Counter(tokens)\n",
        "print(word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYbNRUNOaJBy",
        "outputId": "75cb1829-af28-48ae-b432-9b7982a03b9d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({',': 5, 'a': 5, '.': 5, 'and': 4, '’': 4, 'they': 4, 'the': 4, 'their': 3, 'child': 3, 'to': 3, 'This': 2, 'story': 2, 'two': 2, 's': 2, 'The': 2, 'fairies': 2, 'them': 2, 'have': 2, 'never': 2, 'is': 2, 'of': 2, 'centers': 1, 'around': 1, 'Titania': 1, 'Oberon': 1, 'fairy': 1, 'characters': 1, 'from': 1, 'Shakespeare': 1, 'famous': 1, 'play': 1, '“': 1, 'A': 1, 'Midsummer': 1, 'Night': 1, 'Dream.': 1, '”': 1, 'are': 1, 'having': 1, 'rough': 1, 'time': 1, 'in': 1, 'marriage': 1, 'when': 1, 'find': 1, 'human': 1, 'They': 1, 'decide': 1, 'adopt': 1, 'him': 1, 'hoping': 1, 'that': 1, 'he': 1, 'll': 1, 'help': 1, 'save': 1, 'relationship': 1, 'However': 1, 'develops': 1, 'deadly': 1, 'modern': 1, 'disease': 1, 'no': 1, 'idea': 1, 'what': 1, 'do': 1, 'since': 1, 'known': 1, 'illness': 1, 'or': 1, 'death': 1, 'tragic': 1, 'tale': 1, 'about': 1, 'how': 1, 'try': 1, 'understand': 1, 'something': 1, 've': 1, 'seen': 1, 'before': 1, 'deep': 1, 'love': 1, 'for': 1, 'stranger': 1, 'who': 1, 'so': 1, 'unlike': 1, 'explores': 1, 'grief': 1, 'parenthood': 1, 'uncertainty': 1, 'knowing': 1, 'whether': 1, 'your': 1, 'will': 1, 'ever': 1, 'even': 1, 'know': 1, 'you': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_word_counts = sorted(word_counts.items(), key = lambda x: x[1], reverse=True)\n",
        "# for word, count in sorted_word_counts:\n",
        "#   print(f'(word): {count}')"
      ],
      "metadata": {
        "id": "fK7D131ZabSz"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sinh n-gram\n",
        "from nltk import ngrams\n",
        "bigrams = list(ngrams (tokens, 2))\n",
        "print(bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98KZB-cJblSz",
        "outputId": "d421384a-eff2-47ea-9b5b-1deb940386e3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'story'), ('story', 'centers'), ('centers', 'around'), ('around', 'Titania'), ('Titania', 'and'), ('and', 'Oberon'), ('Oberon', ','), (',', 'two'), ('two', 'fairy'), ('fairy', 'characters'), ('characters', 'from'), ('from', 'Shakespeare'), ('Shakespeare', '’'), ('’', 's'), ('s', 'famous'), ('famous', 'play'), ('play', ','), (',', '“'), ('“', 'A'), ('A', 'Midsummer'), ('Midsummer', 'Night'), ('Night', '’'), ('’', 's'), ('s', 'Dream.'), ('Dream.', '”'), ('”', 'The'), ('The', 'two'), ('two', 'fairies'), ('fairies', 'are'), ('are', 'having'), ('having', 'a'), ('a', 'rough'), ('rough', 'time'), ('time', 'in'), ('in', 'their'), ('their', 'marriage'), ('marriage', 'when'), ('when', 'they'), ('they', 'find'), ('find', 'a'), ('a', 'human'), ('human', 'child'), ('child', '.'), ('.', 'They'), ('They', 'decide'), ('decide', 'to'), ('to', 'adopt'), ('adopt', 'him'), ('him', ','), (',', 'hoping'), ('hoping', 'that'), ('that', 'he'), ('he', '’'), ('’', 'll'), ('ll', 'help'), ('help', 'them'), ('them', 'save'), ('save', 'their'), ('their', 'relationship'), ('relationship', '.'), ('.', 'However'), ('However', ','), (',', 'the'), ('the', 'child'), ('child', 'develops'), ('develops', 'a'), ('a', 'deadly'), ('deadly', ','), (',', 'modern'), ('modern', 'disease'), ('disease', 'and'), ('and', 'the'), ('the', 'fairies'), ('fairies', 'have'), ('have', 'no'), ('no', 'idea'), ('idea', 'what'), ('what', 'to'), ('to', 'do'), ('do', 'since'), ('since', 'they'), ('they', 'have'), ('have', 'never'), ('never', 'known'), ('known', 'illness'), ('illness', 'or'), ('or', 'death'), ('death', '.'), ('.', 'This'), ('This', 'is'), ('is', 'a'), ('a', 'tragic'), ('tragic', 'tale'), ('tale', 'about'), ('about', 'how'), ('how', 'they'), ('they', 'try'), ('try', 'to'), ('to', 'understand'), ('understand', 'something'), ('something', 'they'), ('they', '’'), ('’', 've'), ('ve', 'never'), ('never', 'seen'), ('seen', 'before'), ('before', 'and'), ('and', 'their'), ('their', 'deep'), ('deep', 'love'), ('love', 'for'), ('for', 'a'), ('a', 'stranger'), ('stranger', 'who'), ('who', 'is'), ('is', 'so'), ('so', 'unlike'), ('unlike', 'them'), ('them', '.'), ('.', 'The'), ('The', 'story'), ('story', 'explores'), ('explores', 'the'), ('the', 'grief'), ('grief', 'of'), ('of', 'parenthood'), ('parenthood', 'and'), ('and', 'the'), ('the', 'uncertainty'), ('uncertainty', 'of'), ('of', 'knowing'), ('knowing', 'whether'), ('whether', 'your'), ('your', 'child'), ('child', 'will'), ('will', 'ever'), ('ever', 'even'), ('even', 'know'), ('know', 'you'), ('you', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams2 = [\"_\".join(x) for x in bigrams]\n",
        "print(bigrams2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs0dAemxbyjA",
        "outputId": "fc27e07c-417a-46f1-8cf2-e95f4820e44e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This_story', 'story_centers', 'centers_around', 'around_Titania', 'Titania_and', 'and_Oberon', 'Oberon_,', ',_two', 'two_fairy', 'fairy_characters', 'characters_from', 'from_Shakespeare', 'Shakespeare_’', '’_s', 's_famous', 'famous_play', 'play_,', ',_“', '“_A', 'A_Midsummer', 'Midsummer_Night', 'Night_’', '’_s', 's_Dream.', 'Dream._”', '”_The', 'The_two', 'two_fairies', 'fairies_are', 'are_having', 'having_a', 'a_rough', 'rough_time', 'time_in', 'in_their', 'their_marriage', 'marriage_when', 'when_they', 'they_find', 'find_a', 'a_human', 'human_child', 'child_.', '._They', 'They_decide', 'decide_to', 'to_adopt', 'adopt_him', 'him_,', ',_hoping', 'hoping_that', 'that_he', 'he_’', '’_ll', 'll_help', 'help_them', 'them_save', 'save_their', 'their_relationship', 'relationship_.', '._However', 'However_,', ',_the', 'the_child', 'child_develops', 'develops_a', 'a_deadly', 'deadly_,', ',_modern', 'modern_disease', 'disease_and', 'and_the', 'the_fairies', 'fairies_have', 'have_no', 'no_idea', 'idea_what', 'what_to', 'to_do', 'do_since', 'since_they', 'they_have', 'have_never', 'never_known', 'known_illness', 'illness_or', 'or_death', 'death_.', '._This', 'This_is', 'is_a', 'a_tragic', 'tragic_tale', 'tale_about', 'about_how', 'how_they', 'they_try', 'try_to', 'to_understand', 'understand_something', 'something_they', 'they_’', '’_ve', 've_never', 'never_seen', 'seen_before', 'before_and', 'and_their', 'their_deep', 'deep_love', 'love_for', 'for_a', 'a_stranger', 'stranger_who', 'who_is', 'is_so', 'so_unlike', 'unlike_them', 'them_.', '._The', 'The_story', 'story_explores', 'explores_the', 'the_grief', 'grief_of', 'of_parenthood', 'parenthood_and', 'and_the', 'the_uncertainty', 'uncertainty_of', 'of_knowing', 'knowing_whether', 'whether_your', 'your_child', 'child_will', 'will_ever', 'ever_even', 'even_know', 'know_you', 'you_.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***a) Liệt kê K (ví dụ K=1000) từ có tần suất xuất hiện nhiều nhất trong một kho văn bản (Corpus) cho trước. ***\n",
        "\n",
        "**b) trong K từ đó không tính stop words**\n",
        "https://huggingface.co/datasets/reuters21578/tree/main/data"
      ],
      "metadata": {
        "id": "VaMooHYwewLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P01VO53MetaH",
        "outputId": "a8de4d20-5336-44e6-aa17-0c21d4f79bfd"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Read the SGML file\n",
        "with open('reut2-000.sgm', 'r', encoding='utf-8') as file:\n",
        "    sgm_content = file.read()\n",
        "\n",
        "# Parse the SGML content using BeautifulSoup\n",
        "soup = BeautifulSoup(sgm_content, 'html.parser')\n",
        "\n",
        "# Find the BODY tag and extract its content\n",
        "body_tag = soup.find_all('body')\n",
        "text = \"\"\n",
        "for lines in body_tag:\n",
        "    text = text + lines.get_text().strip()\n",
        "    print(lines.get_text().strip())"
      ],
      "metadata": {
        "id": "KIQe5uTdotjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
        "stop_vocab = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j65aMjl4pGuT",
        "outputId": "655c8fcc-e0dc-46f0-890c-ad3bfe2b97b7"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getKMost(k):\n",
        "  tokens = word_tokenize(text)\n",
        "  word_counts = Counter(tokens)\n",
        "  sorted_word_counts = sorted(word_counts.items(), key = lambda x:x[1], reverse = True)\n",
        "  i = 0\n",
        "  for word,count in sorted_word_counts:\n",
        "    if word in english_vocab and word not in stop_vocab:\n",
        "      i = i + 1\n",
        "      print(f'{word}: {count}')\n",
        "      if i == k:\n",
        "        break\n",
        "print(getKMost(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW0RzxPOpSPt",
        "outputId": "409d26de-7164-4e56-cd41-ca48977aa87c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "said: 2509\n",
            "billion: 519\n",
            "year: 487\n",
            "would: 420\n",
            "company: 392\n",
            "last: 297\n",
            "market: 275\n",
            "one: 254\n",
            "new: 254\n",
            "loss: 237\n",
            "share: 230\n",
            "also: 223\n",
            "two: 218\n",
            "government: 206\n",
            "stock: 199\n",
            "debt: 183\n",
            "week: 175\n",
            "per: 168\n",
            "oil: 167\n",
            "profit: 150\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "exclude_chars = set(string.punctuation)\n",
        "# Parse the HTML document\n",
        "soup = BeautifulSoup(sgm_content, 'html.parser')\n",
        "\n",
        "# Find all <BODY> tags and extract the text between them\n",
        "body_texts = [body.text for body in soup.find_all('body')]\n",
        "\n",
        "tokens = [word_tokenize(x) for x in body_texts]\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "word_counts = [Counter(token) for token in tokens]\n",
        "word_counts_merge = Counter()\n",
        "\n",
        "for counter in word_counts:\n",
        "    word_counts_merge.update({word: count for word, count in counter.items() if word not in stop_words and word not in exclude_chars})\n",
        "top_1000_words = word_counts_merge.most_common(20)\n",
        "\n",
        "for word, count in top_1000_words:\n",
        "    print(f'{word} : {count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEmwtzqWp8G3",
        "outputId": "bc5a4b53-6143-4e62-dd0d-f3e9da03d1c0"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "said : 2509\n",
            "mln : 1288\n",
            "The : 1188\n",
            "dlrs : 1080\n",
            "\u0003 : 925\n",
            "pct : 897\n",
            "'s : 877\n",
            "vs : 749\n",
            "Reuter : 672\n",
            "'' : 568\n",
            "billion : 519\n",
            "`` : 511\n",
            "year : 487\n",
            "cts : 484\n",
            "would : 420\n",
            "company : 392\n",
            "U.S. : 355\n",
            "last : 297\n",
            "Inc : 290\n",
            "market : 275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}